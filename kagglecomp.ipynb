{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDe3bGntOCIc",
        "outputId": "0e67a8c7-ca7e-4750-de70-562921bdb51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment-analysis-hse-fcl.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c sentiment-analysis-hse-fcl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbgUzIxERDhJ",
        "outputId": "d78a63f8-2508-40da-e7a9-2d2275a73ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/sentiment-analysis-hse-fcl.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvcOXVtzD8Oc",
        "outputId": "a2335189-7ee5-411a-b322-b59978d5c6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfBUAhvmSbNz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import bz2\n",
        "import regex\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import ssl\n",
        "\n",
        "try:\n",
        "    _create_unverified_https_context = ssl._create_unverified_context\n",
        "except AttributeError:\n",
        "    pass\n",
        "else:\n",
        "    ssl._create_default_https_context = _create_unverified_https_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyV2uvYJUUdT"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQuBy52OUaI4",
        "outputId": "9a9dc520-611c-4e1e-878a-cc17487d7c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILyvKnZWUbqe",
        "outputId": "55ba1adc-aa29-40bc-8ebd-c027f6a16a42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3600000it [00:38, 94645.79it/s]\n"
          ]
        }
      ],
      "source": [
        "train_texts = []\n",
        "with open('x_train.txt', 'r', encoding='utf-8') as thefile:\n",
        "    for row in tqdm(thefile):\n",
        "        row = re.sub(r'[^\\w\\s]', '', row)\n",
        "        row = row.lower()\n",
        "        train_texts.append(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnvRTUkEVDVq",
        "outputId": "1bbc9c66-e48c-4ed4-a6e3-a18a1bbe107b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a little much for a kids book has quite a few pretty tasteless racial and adulttype comments that is likely why it is no longer in print\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(train_texts[354146])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUnNv9FwVnd5"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('y_train.csv')['Probability'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymNOSVNfV1m1"
      },
      "outputs": [],
      "source": [
        "max_features = 20000\n",
        "maxlen = 100\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbC0mi2OV3E9",
        "outputId": "e4611139-2075-477c-ef4e-b8e4c63966e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [00:12<00:00, 4008.29it/s]\n"
          ]
        }
      ],
      "source": [
        "lem_texts = []\n",
        "for text in tqdm(train_texts[:50000]):\n",
        "    lem_texts.append(' '.join([lemmatizer.lemmatize(word) for word in text.split()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "qzhJoK4ndW57",
        "outputId": "96ba3e7f-e9e1-4513-cefa-4d197c5bd9b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'textbook book shipped quickly and wa in excellent condition a stated easy transaction would buy again'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "lem_texts[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO3HxQKzdaiT",
        "outputId": "c39e2129-12ee-406f-c689-a1bef7a54894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.44 s, sys: 48.8 ms, total: 2.49 s\n",
            "Wall time: 2.48 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "vectorizer = TfidfVectorizer(encoding='utf8', min_df=10)\n",
        "_ = vectorizer.fit(lem_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOnXNIdYfN6Q"
      },
      "outputs": [],
      "source": [
        "X = vectorizer.transform(lem_texts[:50000])\n",
        "Y = (np.array(ratings[:50000])).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at6I2eSgfmka",
        "outputId": "47740ace-415e-476a-e9c4-c6e235523c76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<50000x11719 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 2577478 stored elements in Compressed Sparse Row format>,\n",
              " array([1, 1, 1, ..., 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jMCDAcxfpXf"
      },
      "outputs": [],
      "source": [
        "X = X.tocoo()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdPYFatCfuUY",
        "outputId": "e1bc3957-cdf8-45c7-d848-ffb662299bfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<50000x11719 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2577478 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ7G8dPgfwYB"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.7, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfMPJjNMfz9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de64ef56-1ac4-452e-bc8b-e8be427b0fa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<15000x11719 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 776746 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbotFAPnf6Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9fc353d-fa69-46f4-8dcb-b65c83eabef6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<35000x11719 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1800732 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir94exhaf6x4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3901077-37e0-4a6f-d446-7e00c568b343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<50000x11719 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2577478 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9He6s_4f-T_"
      },
      "outputs": [],
      "source": [
        "def sp2tensor(X):\n",
        "    values = X.data\n",
        "    indices = np.vstack((X.row, X.col))\n",
        "\n",
        "    i = torch.LongTensor(indices)\n",
        "    v = torch.FloatTensor(values)\n",
        "    shape = X.shape\n",
        "\n",
        "    X_t = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
        "    return X_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxmp8dlYgCBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e531891-385e-4c1b-efad-bb5803960380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-2f9e3428c0e7>:9: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:621.)\n",
            "  X_t = torch.sparse.FloatTensor(i, v, torch.Size(shape))\n"
          ]
        }
      ],
      "source": [
        "X_train_t, X_test_t = sp2tensor(X_train.tocoo()), sp2tensor(X_test.tocoo())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_t = torch.Tensor(y_train)\n",
        "y_test_t = torch.Tensor(y_test)\n",
        "X_train_dense = torch.tensor(X_train.toarray(), dtype=torch.float32).unsqueeze(1)\n",
        "X_test_dense = torch.tensor(X_test.toarray(), dtype=torch.float32).unsqueeze(1)"
      ],
      "metadata": {
        "id": "kboiIFXfFNfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.2):\n",
        "        super(SentimentRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def dense_collate_fn(batch):\n",
        "    reviews, labels = zip(*batch)\n",
        "    reviews = torch.stack(reviews)\n",
        "    labels = torch.stack(labels)\n",
        "    return reviews, labels\n",
        "\n",
        "# гиперпараметры\n",
        "input_size = X_train_dense.shape[2]\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "num_layers = 3\n",
        "dropout = 0.3\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = SentimentRNN(input_size, hidden_size, output_size, num_layers)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "X_train_dense = torch.tensor(X_train.toarray(), dtype=torch.float32).unsqueeze(1)\n",
        "X_test_dense = torch.tensor(X_test.toarray(), dtype=torch.float32).unsqueeze(1)\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train_dense, y_train_t)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_dense, y_test_t)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=dense_collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=dense_collate_fn)\n",
        "\n",
        "# обучение\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (reviews, labels) in enumerate(train_loader):\n",
        "        outputs = model(reviews)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_nQHRT8xEXz",
        "outputId": "8c8d8a44-86bb-4697-e09c-5d67e4dff37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/235], Loss: 0.3316\n",
            "Epoch [1/10], Step [200/235], Loss: 0.3115\n",
            "Epoch [2/10], Step [100/235], Loss: 0.1418\n",
            "Epoch [2/10], Step [200/235], Loss: 0.1008\n",
            "Epoch [3/10], Step [100/235], Loss: 0.1204\n",
            "Epoch [3/10], Step [200/235], Loss: 0.1636\n",
            "Epoch [4/10], Step [100/235], Loss: 0.0333\n",
            "Epoch [4/10], Step [200/235], Loss: 0.2350\n",
            "Epoch [5/10], Step [100/235], Loss: 0.0144\n",
            "Epoch [5/10], Step [200/235], Loss: 0.0200\n",
            "Epoch [6/10], Step [100/235], Loss: 0.0109\n",
            "Epoch [6/10], Step [200/235], Loss: 0.0162\n",
            "Epoch [7/10], Step [100/235], Loss: 0.0136\n",
            "Epoch [7/10], Step [200/235], Loss: 0.0399\n",
            "Epoch [8/10], Step [100/235], Loss: 0.0019\n",
            "Epoch [8/10], Step [200/235], Loss: 0.0416\n",
            "Epoch [9/10], Step [100/235], Loss: 0.0023\n",
            "Epoch [9/10], Step [200/235], Loss: 0.0108\n",
            "Epoch [10/10], Step [100/235], Loss: 0.0146\n",
            "Epoch [10/10], Step [200/235], Loss: 0.0436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for reviews, labels in test_loader:\n",
        "        outputs = model(reviews)\n",
        "        predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the test data: {100 * correct / total:.2f}%') \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "-Uw02UyPyrTu",
        "outputId": "8fbd265d-a496-4450-f10b-1f0ce9f0ed73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" model.eval()\\nwith torch.no_grad():\\n    correct = 0\\n    total = 0\\n    for reviews, labels in test_loader:\\n        outputs = model(reviews)\\n        predicted = (torch.sigmoid(outputs.squeeze()) > 0.5).float()\\n        total += labels.size(0)\\n        correct += (predicted == labels).sum().item()\\n\\n    print(f'Accuracy of the model on the test data: {100 * correct / total:.2f}%') \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "test_texts = []\n",
        "with open('x_test.txt', 'r', encoding='utf-8') as f:\n",
        "    for row in f:\n",
        "        row = re.sub(r'[^\\w\\s]', '', row)\n",
        "        row = row.lower()\n",
        "        test_texts.append(row)\n",
        "\n",
        "X_fin_test = vectorizer.transform(test_texts)\n",
        "X_fin_test_dense = torch.tensor(X_fin_test.toarray(), dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "fin_test_dataset = TensorDataset(X_fin_test_dense)\n",
        "fin_test_loader = DataLoader(dataset=fin_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Ai3MhTmn6zAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_to_csv(predictions, file_path):\n",
        "    ids = list(range(1, len(predictions) + 1))\n",
        "    df = pd.DataFrame(list(zip(ids, predictions)), columns=['ID', 'Probability'])\n",
        "    df.to_csv(file_path, index=False)\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "print('Saving...')\n",
        "with torch.no_grad():\n",
        "    for reviews in tqdm(fin_test_loader):\n",
        "        outputs = model(reviews[0])\n",
        "        predicted_probs = torch.sigmoid(outputs.squeeze()).numpy()\n",
        "        predictions.extend(predicted_probs)\n",
        "\n",
        "save_predictions_to_csv(predictions, 'submission.csv')\n",
        "\n",
        "print(\"Predictions saved to submission.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-n4UByN-Jtj",
        "outputId": "cba18348-e3aa-4d5b-fe13-c3c3513430a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6250/6250 [00:19<00:00, 313.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to submission.csv.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}